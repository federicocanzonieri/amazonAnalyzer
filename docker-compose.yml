version: "3.7"
services:
    python:
        build:
            context: ./python
            dockerfile: Dockerfile
        image: am:python
        container_name: python_AM
        networks:
            tap:
                ipv4_address: 10.0.100.3
        environment:
            CODE_PRODUCT: B093T7GQWB
            PYTHON_APP: amazonScraper.py
            HOST_LOGSTASH: 10.0.100.2
            PORT_LOGSTASH: 6000
            TIMEOUT_BEFORE_LOGSTASH: 100
            TIMEOUT_FETCH_ANOTHER_PAGE: 5
            DEBUG: "no"
            START_PAGE: 0
            END_PAGE: 6
        depends_on:
            - logstash
    logstash:
        build:
            context: ./logstash
            dockerfile: Dockerfile
        image: am:logstash
        container_name: logstash_AM
        networks:
            tap:
                ipv4_address: 10.0.100.2
        volumes:
            - $PWD/logstash/pipeline/:/usr/share/logstash/pipeline/
        ports:
            - 6000:6000
        environment:
            TCP_PORT: 6000
        depends_on:
            - kafka_server
    zookeeper:
        build:
            context: ./kafka
            dockerfile: Dockerfile
        image: am:zookeeper
        container_name: zookeeper_AM
        networks: 
            tap:
                ipv4_address: 10.0.100.22
        ports:
            - 2181:2181
        environment: 
            KAFKA_ACTION: start-zk
    
    kafka_server:
        build:
            context: ./kafka
            dockerfile: Dockerfile
        image: am:kafka_server
        container_name: kafka_server_AM
        networks: 
            tap:
                ipv4_address: 10.0.100.23
        ports:
            - 9092:9092
        environment: 
            KAFKA_ACTION: start-kafka
        depends_on: 
            - zookeeper
    
    # spark:
    #     build:
    #         context: ./spark
    #         dockerfile: Dockerfile
    #     image: am:spark
    #     container_name: spark_AM
    #     networks:
    #         tap:
    #             ipv4_address: 10.0.100.80
    #     environment:
    #         SPARK_ACTION: "spark-submit-python"
    #         #TAP_CODE: app.py
    #     command: ["python3","/opt/tap/app.py", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.1,org.elasticsearch:elasticsearch-spark-30_2.12:7.12.1"]
    #     depends_on:
    #         - kafka_server
    
    webui:
        image: provectuslabs/kafka-ui:latest
        container_name: kafkaWebUI_AM
        environment:
            - KAFKA_CLUSTERS_0_NAME=local
            - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=10.0.100.23:9092
        ports: 
            - 8080:8080
        networks: 
            - tap
        depends_on:
            - kafka_server
    
    elastic_search:
        build:
            context: ./elastic
            dockerfile: Dockerfile
        image: am:elastic_search
        container_name: elastic_search_AM
        networks: 
            tap:
                ipv4_address: 10.0.100.51
        ports:
            - 9200:9200
            - 9300:9300
        environment:
            discovery.type: single-node
            ES_JAVA_OPTS: -Xms4g -Xmx4g
            #KAFKA_ACTION: start-kafka
    
    kibana:
        build:
            context: ./kibana
            dockerfile: Dockerfile
        image: am:kibana
        container_name: kibana_AM
        networks: 
            tap:
                ipv4_address: 10.0.100.52
        ports:
            - 5601:5601
            

networks: 
    tap:
        name: tap
        driver: bridge
        ipam:
            config:
                - subnet: 10.0.100.1/24
    
  


        